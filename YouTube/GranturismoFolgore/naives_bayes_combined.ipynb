{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model code is provided by https://github.com/twistedTightly/NLP-Age-Classification/blob/master/src/naive_bayes_combined.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined bag of words: word unigrams and bigrams plus POS n-grams, all in a naive bayes classifier\n",
    "\n",
    "import math\n",
    "\n",
    "class naive_bayes_combined:\n",
    "\tdef __init__(self, trainData = None):\n",
    "\t\tif trainData != None: #Train if the training data has been provided\n",
    "\t\t\tself.train(trainData)\n",
    "\n",
    "\tdef train(self, trainingData):\n",
    "\t\t#Set categories\n",
    "\t\tcategories = ['10', '20', '30', '40']\n",
    "\n",
    "\t\t#Create data structures for word counts and category counts\n",
    "\t\twordCounts = dict()\n",
    "\t\tcategoryDocumentCounts = dict()\n",
    "\t\tcategoryWordCounts = dict()\n",
    "\t\twordProbs = dict()\n",
    "\t\tfor category in categories:\n",
    "\t\t\twordCounts[category] = dict()\n",
    "\t\t\tcategoryDocumentCounts[category] = 0\n",
    "\t\t\tcategoryWordCounts[category] = 0\n",
    "\t\t\twordProbs[category] = dict()\n",
    "\t\tnumDocuments = 0\n",
    "\t\tvocabSet = set()\n",
    "\n",
    "\t\t#Read through each line; count and divide\n",
    "\t\tfor line in trainingData:\n",
    "\t\t\twords = line.rstrip().split()\n",
    "\t\n",
    "\t\t\t#Separate first element (category) from the rest of the words\n",
    "\t\t\tcategory = words[0]\n",
    "\t\t\twords = words[1:]\n",
    "\n",
    "\t\t\t#Process the category\n",
    "\t\t\tif category not in categories:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tcategoryDocumentCounts[category] += 1\n",
    "\t\t\tnumDocuments += 1\n",
    "\n",
    "\t\t\t#Count words\n",
    "\t\t\tfor word in words:\n",
    "\t\t\t\tparts = word.split(\"/\")\n",
    "\n",
    "\t\t\t\t#Parse to get the actual word\n",
    "\t\t\t\tif len(parts) != 3:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tword = parts[0]\n",
    "\t\t\t\tpos = parts[1]\n",
    "\t\t\t\tsentencePart = parts[2]\n",
    "\t\t\n",
    "\t\t\t\tif word not in wordCounts[category]:\n",
    "\t\t\t\t\twordCounts[category][word] = 0\n",
    "\n",
    "\t\t\t\twordCounts[category][word] += 50\n",
    "\t\t\t\tcategoryWordCounts[category] += 50\n",
    "\t\t\t\tvocabSet.add(word)\n",
    "\n",
    "\t\t\t#Count bigrams\n",
    "\t\t\tprevWord = words[0].split(\"/\")[0]\n",
    "\t\t\tfor word in words[1:]:\n",
    "\t\t\t\tparts = word.split(\"/\")\n",
    "\t\n",
    "\t\t\t\t#Parse to get the actual word\n",
    "\t\t\t\tif len(parts) != 3:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tword = parts[0]\n",
    "\t\t\t\tpos = parts[1]\n",
    "\t\t\t\tsentencePart = parts[2]\n",
    "\n",
    "\t\t\t\tbigram = prevWord + \" \" + word\n",
    "\n",
    "\t\t\t\tif bigram not in wordCounts[category]:\n",
    "\t\t\t\t\twordCounts[category][bigram] = 0\n",
    "\n",
    "\t\t\t\twordCounts[category][bigram] += 50\n",
    "\t\t\t\tcategoryWordCounts[category] += 50\n",
    "\t\t\t\tvocabSet.add(bigram)\n",
    "\n",
    "\t\t\t\tprevWord = word\n",
    "\n",
    "\t\t\t#Construct tag sequence\n",
    "\t\t\ttagSequence = [\"<s>\"]\n",
    "\t\t\tfor word in words:\n",
    "\t\t\t\tparts = word.split(\"/\")\n",
    "\t\t\t\tpos = parts[1]\n",
    "\t\t\t\ttagSequence.append(pos)\n",
    "\t\t\ttagSequence.append(\"</s>\")\n",
    "\n",
    "\t\t\t#Construct all of the tag n-grams that can be used, for n=3,4\n",
    "\t\t\ttagNGrams = []\n",
    "\n",
    "\t\t\t#Add trigrams\n",
    "\t\t\tprevPrevTag = tagSequence[0]\n",
    "\t\t\tprevTag = tagSequence[1]\n",
    "\t\t\tfor tag in tagSequence[2:]:\n",
    "\t\t\t\ttagTrigram = prevPrevTag + \"/\" + prevTag + \"/\" + tag\n",
    "\t\t\t\ttagNGrams.append(tagTrigram)\t\n",
    "\t\t\t\tprevPrevTag = prevTag\n",
    "\t\t\t\tprevTag = tag\t\n",
    "\n",
    "\t\t\t#Add 4-grams (only if the tag sequence has at least 4 tags, meaning it's at least two words plus <s> and </s>\n",
    "\t\t\tif len(tagSequence) >= 4:\n",
    "\t\t\t\tprevPrevPrevTag = tagSequence[0]\n",
    "\t\t\t\tprevPrevTag = tagSequence[1]\t\n",
    "\t\t\t\tprevTag = tagSequence[2]\n",
    "\t\t\t\tfor tag in tagSequence[3:]:\n",
    "\t\t\t\t\ttag4Gram = prevPrevPrevTag + \"/\" + prevPrevTag + \"/\" + prevTag + \"/\" + tag\n",
    "\t\t\t\t\ttagNGrams.append(tag4Gram)\n",
    "\t\t\t\t\tprevPrevPrevTag = prevPrevTag\n",
    "\t\t\t\t\tprevPrevTag = prevTag\n",
    "\t\t\t\t\tprevTag = tag\t\n",
    "\n",
    "\t\t\t#Add these tag trigrams and 4-grams to the bag of words\n",
    "\t\t\tfor tagNGram in tagNGrams:\n",
    "\t\t\t\tif tagNGram not in wordCounts[category]:\n",
    "\t\t\t\t\twordCounts[category][tagNGram] = 0\n",
    "\n",
    "\t\t\t\twordCounts[category][tagNGram] += 1\n",
    "\t\t\t\tcategoryWordCounts[category] += 1\n",
    "\t\t\t\tvocabSet.add(tagNGram)\n",
    "\n",
    "\t\t#Set up smoothing\n",
    "\t\tdelta = 100\n",
    "\t\tvocabSize = len(vocabSet)\n",
    "\n",
    "\t\t#Calculate probabilities for each category\n",
    "\t\tcategoryProbs = dict()\n",
    "\t\tfor category in categories:\n",
    "\t\t\tcategoryProbs[category] = float(categoryDocumentCounts[category]) / numDocuments\n",
    "\t\n",
    "\t\t#Calculate probabilities for each word\n",
    "\t\tfor category in categories:\n",
    "\t\t\tfor word in wordCounts[category]:\n",
    "\t\t\t\twordProbs[category][word] = ( float(wordCounts[category][word]) + delta ) / ( categoryWordCounts[category] + vocabSize*delta )\n",
    "\n",
    "\t\t#Calculate probabilities for unknown words\n",
    "\t\tunknownWordProb = dict()\n",
    "\t\tfor category in categories:\n",
    "\t\t\tunknownWordProb[category] = float(delta) / ( categoryWordCounts[category] + vocabSize*delta )\n",
    "\n",
    "\t\t#Save relevant data structures\n",
    "\t\tself.wordProbs = wordProbs\n",
    "\t\tself.unknownWordProb = unknownWordProb\n",
    "\t\tself.categories = categories\n",
    "\n",
    "\tdef decode(self, words, tagSequence):\n",
    "\t\t#Get relevant data structures\n",
    "\t\twordProbs = self.wordProbs\n",
    "\t\tunknownWordProb = self.unknownWordProb\n",
    "\t\tcategories = self.categories\n",
    "\n",
    "\t\t#Construct all of the tag n-grams that can be used, for n=3,4\n",
    "\t\ttagNGrams = []\n",
    "\n",
    "\t\t#Add trigrams\n",
    "\t\tprevPrevTag = tagSequence[0]\n",
    "\t\tprevTag = tagSequence[1]\n",
    "\t\tfor tag in tagSequence[2:]:\n",
    "\t\t\ttagTrigram = prevPrevTag + \"/\" + prevTag + \"/\" + tag\n",
    "\t\t\ttagNGrams.append(tagTrigram)\t\n",
    "\t\t\tprevPrevTag = prevTag\n",
    "\t\t\tprevTag = tag\t\n",
    "\n",
    "\t\t#Add 4-grams (only if the tag sequence has at least 4 tags, meaning it's at least two words plus <s> and </s>\n",
    "\t\tif len(tagSequence) >= 4:\n",
    "\t\t\tprevPrevPrevTag = tagSequence[0]\n",
    "\t\t\tprevPrevTag = tagSequence[1]\t\n",
    "\t\t\tprevTag = tagSequence[2]\n",
    "\t\t\tfor tag in tagSequence[3:]:\n",
    "\t\t\t\ttag4Gram = prevPrevPrevTag + \"/\" + prevPrevTag + \"/\" + prevTag + \"/\" + tag\n",
    "\t\t\t\ttagNGrams.append(tag4Gram)\n",
    "\t\t\t\tprevPrevPrevTag = prevPrevTag\n",
    "\t\t\t\tprevPrevTag = prevTag\n",
    "\t\t\t\tprevTag = tag\t\n",
    "\n",
    "\t\t#Add up log probabilities for each word and n-gram, for each category:\n",
    "\t\tthisLineLogProb = dict()\n",
    "\t\tfor category in categories:\n",
    "\t\t\tthisLineLogProb[category] = 0\t\n",
    "\n",
    "\t\t\t#Count word unigrams\n",
    "\t\t\tfor word in words:\n",
    "\t\t\t\tparts = word.split(\"/\")\n",
    "\n",
    "\t\t\t\t#Parse to get the actual word\n",
    "\t\t\t\tif len(parts) != 3:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tword = parts[0]\n",
    "\t\t\t\tpos = parts[1]\n",
    "\t\t\t\tsentencePart = parts[2]\n",
    "\n",
    "\t\t\t\t#Increment probability\n",
    "\t\t\t\tif word in wordProbs[category]:\n",
    "\t\t\t\t\tthisWordProb = wordProbs[category][word]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tthisWordProb = unknownWordProb[category]\n",
    "\t\t\t\tthisLineLogProb[category] += math.log10(thisWordProb)\n",
    "\n",
    "\t\t\t#Count bigrams\n",
    "\t\t\tprevWord = words[0].split(\"/\")[0]\n",
    "\t\t\tfor word in words[1:]:\n",
    "\t\t\t\tparts = word.split(\"/\")\n",
    "\t\n",
    "\t\t\t\t#Parse to get the actual word\n",
    "\t\t\t\tif len(parts) != 3:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tword = parts[0]\n",
    "\t\t\t\tpos = parts[1]\n",
    "\t\t\t\tsentencePart = parts[2]\n",
    "\n",
    "\t\t\t\tbigram = prevWord + \" \" + word\n",
    "\n",
    "\t\t\t\t#Increment probability\n",
    "\t\t\t\tif bigram in wordProbs[category]:\n",
    "\t\t\t\t\tthisWordProb = wordProbs[category][bigram]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tthisWordProb = unknownWordProb[category]\n",
    "\t\t\t\tthisLineLogProb[category] += math.log10(thisWordProb)\n",
    "\n",
    "\t\t\t#Count tag n-grams\n",
    "\t\t\tfor tagNGram in tagNGrams:\n",
    "\t\t\t\t#Increment probability\n",
    "\t\t\t\tif tagNGram in wordProbs[category]:\n",
    "\t\t\t\t\tthisWordProb = wordProbs[category][tagNGram]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tthisWordProb = unknownWordProb[category]\n",
    "\t\t\t\tthisLineLogProb[category] += math.log10(thisWordProb)\n",
    "\n",
    "\t\t#For this line, choose the category with the biggest log prob\n",
    "\t\twinningCategory = max(thisLineLogProb, key=thisLineLogProb.get)\n",
    "\t\t\n",
    "\t\treturn winningCategory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('DigitalTech')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a198fc3a2683bd958433f4d7e447d5eeb9d1c4c7374695088b76366538a7df0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
